# Plan: Improve Memory Usage in Meow

Meow is designed to run in the constrained `no_std` environment of the Akuma kernel. To prevent Out of Memory (OOM) crashes and improve performance, the following improvements are planned.

## 1. Tool Output Overflow to Disk

Currently, tools like `Shell`, `FileList`, and `CodeSearch` capture their entire output in memory before returning it to the LLM. For commands with large outputs, this is the primary cause of OOM.

### Proposal
- **Limit Configuration**: Add `MAX_TOOL_OUTPUT_SIZE` to `src/config.rs` (set to 32KB by default).
- **Disk Offloading**: 
    - In `src/tools.rs`, monitor the size of data being captured from stdout or generated by tools.
    - If the output exceeds `MAX_TOOL_OUTPUT_SIZE`:
        1. Ensure `/tmp/` exists in the sandbox directory (create if missing).
        2. Generate a unique filename (e.g., `/tmp/meow_output_XXXX.txt`).
        3. Write the full output to this file using `libakuma` syscalls.
        4. Return a truncated response to the LLM.
- **LLM Response Format**:
    ```
    [!] Output truncated due to memory limits.
    Full output saved to: /tmp/meow_output_12345.txt
    
    Preview:
    ---
    <first 4KB of output>
    ---
    
    Note: You can use `FileReadLines` to read specific parts of the saved output or `CodeSearch` for targeted investigation nya~!
    ```

## 2. Streaming Response Parser Optimization

The NDJSON streaming parser in `src/main.rs` and `src/tui_app.rs` currently uses inefficient string re-allocation.

### Improvement
- **Before**: `pending_lines = String::from(&pending_lines[newline_pos + 1..]);`
- **After**: `pending_lines.drain(..newline_pos + 1);`
- This avoids multiple heap allocations and copies for every line received from the LLM.

## 3. History and Context Management

### Improvements
- **Aggressive Trimming**: Call `trim_history` and `compact_history` more frequently, especially after large tool results are added.
- **Proactive Compaction**: Automatically trigger a `CompactContext` recommendation if the token count exceeds 75% of the context window.
- **Message Value Shrinking**: Ensure `shrink_to_fit()` is called on message content strings after they are fully received.

## 4. TUI State Efficiency

### Improvements
- **Avoid Clones**: In `tui_app.rs`, the message history is cloned multiple times per turn. Use references where possible.
- **Static Buffer Reuse**: Use reusable buffers for UI rendering instead of allocating new `String` objects for every frame where possible.

## 5. History Memory Indicator

To help users and developers monitor memory pressure from chat history, a new indicator will be added to the TUI.

### Proposal
- **History Size Calculation**: Implement a function to calculate the total byte size of all messages currently in `history`.
- **UI Display**: Add a `Hist: XX KB` indicator to the TUI status bar (footer).
- **Visual Feedback**: Change the indicator color to yellow if history exceeds 128KB, and red if it exceeds 256KB, providing a clear signal to use `/clear` or `CompactContext`.
